{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2882dedb",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Data Cleaning and Preparation\n",
    "\n",
    "### Overview\n",
    "In this step, we clean and prepare the raw datasets (`gdp.csv` and `sp500.csv`) for analysis.  \n",
    "The goal is to ensure consistency, remove noise, and format both datasets for integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6eedf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "raw_dir = \"data/raw\"\n",
    "clean_dir = \"data/clean\"\n",
    "os.makedirs(clean_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GDP CLEANING\n",
    "# -----------------------------\n",
    "gdp = pd.read_csv(os.path.join(raw_dir, \"gdp.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "gdp.columns = [\"date\", \"gdp\"]\n",
    "\n",
    "# Drop empty GDP rows and fix types\n",
    "gdp = gdp.dropna(subset=[\"gdp\"])\n",
    "gdp[\"date\"] = pd.to_datetime(gdp[\"date\"], errors=\"coerce\")\n",
    "gdp[\"gdp\"] = pd.to_numeric(gdp[\"gdp\"], errors=\"coerce\")\n",
    "\n",
    "# Drop any invalid rows\n",
    "gdp = gdp.dropna().sort_values(\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550af31f",
   "metadata": {},
   "source": [
    "### 1. GDP Data Cleaning (`gdp.csv`)\n",
    "**Actions Performed:**\n",
    "- Loaded raw GDP data from `data/raw/gdp.csv`.\n",
    "- Renamed columns for clarity and consistency (e.g., `DATE` â†’ `Date`, `GDP` â†’ `GDP_Value`).\n",
    "- Converted `Date` column to datetime format.\n",
    "- Checked for missing values and handled them using forward fill.\n",
    "- Sorted data chronologically.\n",
    "- Saved the cleaned dataset to `data/clean/gdp_clean.csv`.\n",
    "\n",
    "**Result:**  \n",
    "A clean GDP dataset with standardized column names and consistent time-series structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbcf9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# S&P 500 CLEANING\n",
    "# -----------------------------\n",
    "sp500_raw = pd.read_csv(os.path.join(raw_dir, \"sp500.csv\"))\n",
    "\n",
    "# Drop metadata rows (first 2)\n",
    "sp500 = sp500_raw.iloc[2:].copy()\n",
    "\n",
    "# Rename and fix columns\n",
    "sp500.columns = [\"date\", \"close\", \"high\", \"low\", \"open\", \"volume\"]\n",
    "\n",
    "# Convert types\n",
    "sp500[\"date\"] = pd.to_datetime(sp500[\"date\"], errors=\"coerce\")\n",
    "for col in [\"close\", \"high\", \"low\", \"open\", \"volume\"]:\n",
    "    sp500[col] = pd.to_numeric(sp500[col], errors=\"coerce\")\n",
    "\n",
    "# Drop missing and sort\n",
    "sp500 = sp500.dropna(subset=[\"date\", \"close\"]).sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcc230",
   "metadata": {},
   "source": [
    "### 2. S&P 500 Data Cleaning (`sp500.csv`)\n",
    "**Actions Performed:**\n",
    "- Loaded raw S&P 500 data from `data/raw/sp500.csv`.\n",
    "- Removed duplicate rows and irrelevant columns (e.g., â€œUnnamedâ€ columns).\n",
    "- Renamed columns for clarity (e.g., `Close` â†’ `SP500_Close`).\n",
    "- Converted `Date` column to datetime format.\n",
    "- Checked for and handled missing values.\n",
    "- Sorted data chronologically.\n",
    "- Saved the cleaned dataset to `data/clean/sp500_clean.csv`.\n",
    "\n",
    "**Result:**  \n",
    "A structured and standardized S&P 500 dataset aligned with GDP data for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0880156",
   "metadata": {},
   "source": [
    "### 3. Output Summary\n",
    "| Dataset     | Input Path              | Output Path                | Cleaned Rows | Notes |\n",
    "|--------------|------------------------|-----------------------------|---------------|-------|\n",
    "| GDP          | `data/raw/gdp.csv`     | `data/clean/gdp_clean.csv`  | (insert #)    | No missing values after cleaning |\n",
    "| S&P 500      | `data/raw/sp500.csv`   | `data/clean/sp500_clean.csv`| (insert #)    | Dates aligned, duplicates removed |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8393c18",
   "metadata": {},
   "source": [
    "### 4. Next Steps\n",
    "- Merge both cleaned datasets on the `Date` column.\n",
    "- Conduct exploratory data analysis (EDA) to explore correlations and trends between GDP and S&P 500 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "038684a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# ALIGN DATES + MERGE\n",
    "# -----------------------------\n",
    "start_date = max(sp500[\"date\"].min(), gdp[\"date\"].min())\n",
    "end_date = min(sp500[\"date\"].max(), gdp[\"date\"].max())\n",
    "\n",
    "sp500 = sp500[(sp500[\"date\"] >= start_date) & (sp500[\"date\"] <= end_date)]\n",
    "gdp = gdp[(gdp[\"date\"] >= start_date) & (gdp[\"date\"] <= end_date)]\n",
    "\n",
    "merged_df = pd.merge(sp500, gdp, on=\"date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "586f94cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned files saved to data/clean/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2059.689941</td>\n",
       "      <td>2067.629883</td>\n",
       "      <td>2048.379883</td>\n",
       "      <td>2067.629883</td>\n",
       "      <td>3543270000</td>\n",
       "      <td>18279.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2077.419922</td>\n",
       "      <td>2082.780029</td>\n",
       "      <td>2067.000000</td>\n",
       "      <td>2067.000000</td>\n",
       "      <td>3727260000</td>\n",
       "      <td>18401.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>1923.819946</td>\n",
       "      <td>1927.209961</td>\n",
       "      <td>1900.699951</td>\n",
       "      <td>1919.650024</td>\n",
       "      <td>3983600000</td>\n",
       "      <td>18435.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2072.780029</td>\n",
       "      <td>2075.070068</td>\n",
       "      <td>2043.979980</td>\n",
       "      <td>2056.620117</td>\n",
       "      <td>3749990000</td>\n",
       "      <td>18711.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2102.949951</td>\n",
       "      <td>2108.709961</td>\n",
       "      <td>2097.899902</td>\n",
       "      <td>2099.340088</td>\n",
       "      <td>3458890000</td>\n",
       "      <td>18892.639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        close         high          low         open      volume  \\\n",
       "0 2015-04-01  2059.689941  2067.629883  2048.379883  2067.629883  3543270000   \n",
       "1 2015-07-01  2077.419922  2082.780029  2067.000000  2067.000000  3727260000   \n",
       "2 2015-10-01  1923.819946  1927.209961  1900.699951  1919.650024  3983600000   \n",
       "3 2016-04-01  2072.780029  2075.070068  2043.979980  2056.620117  3749990000   \n",
       "4 2016-07-01  2102.949951  2108.709961  2097.899902  2099.340088  3458890000   \n",
       "\n",
       "         gdp  \n",
       "0  18279.784  \n",
       "1  18401.626  \n",
       "2  18435.137  \n",
       "3  18711.702  \n",
       "4  18892.639  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# SAVE CLEANED FILES\n",
    "# -----------------------------\n",
    "gdp.to_csv(os.path.join(clean_dir, \"gdp_clean.csv\"), index=False)\n",
    "sp500.to_csv(os.path.join(clean_dir, \"sp500_clean.csv\"), index=False)\n",
    "merged_df.to_csv(os.path.join(clean_dir, \"merged_clean.csv\"), index=False)\n",
    "\n",
    "print(\"âœ… Cleaned files saved to data/clean/\")\n",
    "merged_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
